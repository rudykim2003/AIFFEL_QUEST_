{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab1ee8f6",
   "metadata": {},
   "source": [
    "# 2-1. 미니 프로젝트 : 가위바위보 분류기를 만들자\n",
    "\n",
    "### 지난 시간 배운 내용을 바탕으로 가위바위보 분류기를 만들도록 하겠습니다.\n",
    "### 가장 먼저 해야 할 일은 뭘까요? 네, 첫 번째!!!! 데이터를 준비해야 합니다.\n",
    "### 가위바위보 이미지를 모아 놓은 곳은 없으므로, 우리가 직접 사진을 찍어서 모아봅시다.\n",
    "\n",
    "## 라이브러리 버전을 확인해 봅니다\n",
    "\n",
    "### 사용할 라이브러리 버전을 둘러봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a98d2fb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.22.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b689a23b",
   "metadata": {},
   "source": [
    "## 데이터 불러오기 + Resize 하기\n",
    "\n",
    "### 숫자 손글씨의 경우 이미지 크기가 28x28 이었기 때문에, 우리의 가위, 바위, 보 이미지도 28x28로 만들어야 합니다. 이를 위해서는 PIL 라이브러리를 사용해볼 거예요. 그러려면 먼저 라이브러리를 불러와야 겠죠?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9102e48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image \n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b587c5f6",
   "metadata": {},
   "source": [
    "### 이제 가위 이미지를 불러와서 28x28 사이즈로 변경할 겁니다. 아래 코드를 실행해보세요. 이미지의 크기가 28x28 로 바뀌었나요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68766c0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2226834b",
   "metadata": {},
   "source": [
    "### 자 그러면, 바위 이미지도 28x28 로 만들어 볼까요? 아래 빈 칸에 코드를 작성하고, 실행해보세요. 바위 이미지가 모두 28x28로 바뀌어야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f403fc9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "바위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"바위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb9d81e3",
   "metadata": {},
   "source": [
    "### 마지막으로 보 이미지도 28x28로 만들어 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f4fe907",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101  images to be resized.\n",
      "101  images resized.\n",
      "보 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"보 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b4a76d",
   "metadata": {},
   "source": [
    "### 숫자 손글씨 인식기는 mnist.load_data() 라는 함수로 데이터를 읽었던 것 기억하시죠? 여러분들이 아직 코딩에 익숙하지 않을 수 있으므로, 가위, 바위, 보 데이터를 읽을 수 있는 load_data() 함수를 만들어 드릴 거예요. 이 코드를 활용하면 임의의 사진 데이터(ex. 귤이 잘 익었나, 안 익었나? 웃는 얼굴인가, 우는 얼굴인가, 평범한 표정의 얼굴인가? 등)에 적용하실 수 있을 겁니다.\n",
    "\n",
    "### load_data() 함수는 입력으로 이미지가 있는 폴더 위치를 받습니다. 여기서는 rock_scissor_paper 폴더 위치를 적어주면 됩니다. 숫자 손글씨는 0~9 까지의 클래스가 있었던 것 기억하시죠? 가위바위보의 경우 3개의 클래스 즉, 가위: 0, 바위: 1, 보: 2 로 라벨링이 될 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b68cbd32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 301 입니다.\n",
      "x_train shape: (301, 28, 28, 3)\n",
      "y_train shape: (301,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=301):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fe48abd",
   "metadata": {},
   "source": [
    "### 한번 이미지를 불러 볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f825bcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd31ba3",
   "metadata": {},
   "source": [
    "## 딥러닝 네트워크 설계하기\n",
    "\n",
    "### 자 이제 데이터의 준비가 끝났습니다. 이제 여러분들이 가위바위보를 인식하는 딥러닝 네트워크를 설계해 볼까요?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdf558bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                102464    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 195       \n",
      "=================================================================\n",
      "Total params: 122,051\n",
      "Trainable params: 122,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. \n",
    "# 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "n_channel_1=32\n",
    "n_channel_2=64\n",
    "n_dense=64\n",
    "n_train_epoch=20\n",
    "\n",
    "model=keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3,3), activation='relu', input_shape=(28,28,3)))\n",
    "model.add(keras.layers.MaxPool2D(2,2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3,3), activation='relu'))\n",
    "model.add(keras.layers.MaxPooling2D((2,2)))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ab09a0",
   "metadata": {},
   "source": [
    "## 딥러닝 네트워크 학습시키기\n",
    "\n",
    "### 잘 설계가 되었다면, 이제 학습을 시켜봅시다. 아마도 여러분들의 데이터는 거의 비슷비슷할 것이기 때문에 accuracy가 꽤 높게 나올 것입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b46c291c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 1s 41ms/step - loss: 36.4978 - accuracy: 0.3754\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 3.8311 - accuracy: 0.4020\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 1.4671 - accuracy: 0.3555\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 1.1157 - accuracy: 0.4186\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 1.2648 - accuracy: 0.3223\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 1.0071 - accuracy: 0.4917\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.9177 - accuracy: 0.5914\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.8911 - accuracy: 0.5648\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.9053 - accuracy: 0.5980\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.9517 - accuracy: 0.5814\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.8270 - accuracy: 0.6179\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.7458 - accuracy: 0.6944\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 38ms/step - loss: 0.7758 - accuracy: 0.6478\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 43ms/step - loss: 0.6892 - accuracy: 0.7375\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 40ms/step - loss: 0.6188 - accuracy: 0.7807\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.5856 - accuracy: 0.8040\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 41ms/step - loss: 0.5422 - accuracy: 0.8173\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 35ms/step - loss: 0.4927 - accuracy: 0.8472\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 42ms/step - loss: 0.5832 - accuracy: 0.7674\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 36ms/step - loss: 0.5545 - accuracy: 0.7741\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x78b35c11c940>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요. \n",
    "# Hint! model.compile()과 model.fit()을 사용해 봅시다.\n",
    "model.compile(optimizer='adam',\n",
    "             loss='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# 모델 훈련\n",
    "model.fit(x_train, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89832f4",
   "metadata": {},
   "source": [
    "# 얼마나 잘 만들었는지 확인하기(테스트)\n",
    "\n",
    "### 여러분들은 300장의 가위바위보 이미지를 만들어 모두 학습에 사용했습니다. 그러므로 테스트 데이터가 없죠. 옆 친구의 이미지 데이터 300장을 받아오세요. 그리고 그것을 테스트 데이터로 하여 test accuracy를 측정해보세요. (만약 웹캠이 없는 경우 섹션을 진행하신 경우, 이미 test 데이터셋이 준비돼있으니 친구에게 조르지 않으셔도 됩니다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "52b1e952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (301, 28, 28, 3)\n",
      "y_test shape: (301,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028bf84e",
   "metadata": {},
   "source": [
    "### 테스트용 데이터가 준비되었으니, 위에서 훈련시킨 model을 사용하여 test_accuracy를 측정해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7faf8e6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 1.7646 - accuracy: 0.3090\n",
      "test_loss: 1.7645916938781738 \n",
      "test_accuracy: 0.3089700937271118\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))\n",
    "\n",
    "# 결과 1번) params: n_channel_1=16, n_channel_2=32, n_dense=32, n_train_epoch=10 -> test_accuracy: 0.1960\n",
    "\n",
    "# 결과 2번) params: n_channel_1=32, n_channel_2=64, n_dense=64, n_train_epoch=20 -> test_accuacy: 0.3090"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2a1c81",
   "metadata": {},
   "source": [
    "## 더 좋은 네트워크 만들어보기\n",
    "\n",
    "### 시험용 데이터x_test에 대한 인식률 test accuracy가 train accuracy보다 많이 낮게 나오지는 않았나요? 만약 그렇다면 그 이유는 무엇일까요? MNIST 손글씨 데이터 때처럼 test accuracy가 train accuracy에 근접하도록 개선 방법을 찾아 봅시다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
