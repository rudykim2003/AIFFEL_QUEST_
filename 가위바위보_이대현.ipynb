{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dffd89e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.0\n",
      "1.22.2\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4e94c54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIL 라이브러리 import 완료!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image \n",
    "import glob\n",
    "import os\n",
    "\n",
    "print(\"PIL 라이브러리 import 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce9f69a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "가위 이미지 resize 완료!\n"
     ]
    }
   ],
   "source": [
    "def resize_images(img_path):\n",
    "\timages=glob.glob(img_path + \"/*.jpg\")  \n",
    "    \n",
    "\tprint(len(images), \" images to be resized.\")\n",
    "\n",
    "    # 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "\ttarget_size=(28,28)\n",
    "\tfor img in images:\n",
    "\t\told_img=Image.open(img)\n",
    "\t\tnew_img=old_img.resize(target_size,Image.ANTIALIAS)\n",
    "\t\tnew_img.save(img, \"JPEG\")\n",
    "    \n",
    "\tprint(len(images), \" images resized.\")\n",
    "\t\n",
    "# 가위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "print(\"가위 이미지 resize 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf1b8cbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n"
     ]
    }
   ],
   "source": [
    "# 바위 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/rock\"\n",
    "\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "resize_images(image_dir_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fa1aa3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n"
     ]
    }
   ],
   "source": [
    "# 보 이미지가 저장된 디렉토리 아래의 모든 jpg 파일을 읽어들여서\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/paper\"\n",
    "# 파일마다 모두 28x28 사이즈로 바꾸어 저장합니다.\n",
    "resize_images(image_dir_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c6910a80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_train shape: (300, 28, 28, 3)\n",
      "y_train shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def load_data(img_path, number_of_data=300):  # 가위바위보 이미지 개수 총합에 주의하세요.\n",
    "    # 가위 : 0, 바위 : 1, 보 : 2\n",
    "    img_size=28\n",
    "    color=3\n",
    "    #이미지 데이터와 라벨(가위 : 0, 바위 : 1, 보 : 2) 데이터를 담을 행렬(matrix) 영역을 생성합니다.\n",
    "    imgs=np.zeros(number_of_data*img_size*img_size*color,dtype=np.int32).reshape(number_of_data,img_size,img_size,color)\n",
    "    labels=np.zeros(number_of_data,dtype=np.int32)\n",
    "\n",
    "    idx=0\n",
    "    for file in glob.iglob(img_path+'/scissor/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=0   # 가위 : 0\n",
    "        idx=idx+1\n",
    "\n",
    "    for file in glob.iglob(img_path+'/rock/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=1   # 바위 : 1\n",
    "        idx=idx+1  \n",
    "    \n",
    "    for file in glob.iglob(img_path+'/paper/*.jpg'):\n",
    "        img = np.array(Image.open(file),dtype=np.int32)\n",
    "        imgs[idx,:,:,:]=img    # 데이터 영역에 이미지 행렬을 복사\n",
    "        labels[idx]=2   # 보 : 2\n",
    "        idx=idx+1\n",
    "        \n",
    "    print(\"학습데이터(x_train)의 이미지 개수는\", idx,\"입니다.\")\n",
    "    return imgs, labels\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper\"\n",
    "(x_train, y_train)=load_data(image_dir_path)\n",
    "x_train_norm = x_train/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "\n",
    "print(\"x_train shape: {}\".format(x_train.shape))\n",
    "print(\"y_train shape: {}\".format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4968eb62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "라벨:  0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(x_train[0])\n",
    "print('라벨: ', y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d885c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 64)        1792      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 26, 26, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 11, 11, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               1638912   \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 1,716,867\n",
      "Trainable params: 1,716,483\n",
      "Non-trainable params: 384\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from tensorflow.keras.layers import BatchNormalization, Dropout\n",
    "# model을 직접 만들어 보세요.\n",
    "# Hint! model의 입력/출력부에 특히 유의해 주세요. 가위바위보 데이터셋은 MNIST 데이터셋과 어떤 점이 달라졌나요?\n",
    "n_channel_1 = 64\n",
    "n_channel_2 = 128\n",
    "n_dense = 512\n",
    "n_train_epoch = 28\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "model.add(keras.layers.Conv2D(n_channel_1, (3, 3), activation='relu', input_shape=(28, 28, 3)))\n",
    "model.add(BatchNormalization())  # 배치 정규화 추가\n",
    "model.add(keras.layers.MaxPooling2D(2, 2))\n",
    "model.add(keras.layers.Conv2D(n_channel_2, (3, 3), activation='relu'))\n",
    "model.add(BatchNormalization())  # 배치 정규화 추가\n",
    "model.add(keras.layers.MaxPooling2D(2, 2))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(n_dense, activation='relu'))\n",
    "model.add(Dropout(0.7))  # 드롭아웃 추가\n",
    "model.add(keras.layers.Dense(3, activation='softmax'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "815770be",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.00055),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f1c1068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/28\n",
      "10/10 [==============================] - 2s 130ms/step - loss: 1.5479 - accuracy: 0.5967\n",
      "Epoch 2/28\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.4242 - accuracy: 0.8500\n",
      "Epoch 3/28\n",
      "10/10 [==============================] - 1s 130ms/step - loss: 0.1669 - accuracy: 0.9433\n",
      "Epoch 4/28\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.1158 - accuracy: 0.9800\n",
      "Epoch 5/28\n",
      "10/10 [==============================] - 1s 122ms/step - loss: 0.0995 - accuracy: 0.9600\n",
      "Epoch 6/28\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.0908 - accuracy: 0.9767\n",
      "Epoch 7/28\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.1024 - accuracy: 0.9633\n",
      "Epoch 8/28\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0803 - accuracy: 0.9700\n",
      "Epoch 9/28\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0663 - accuracy: 0.9700\n",
      "Epoch 10/28\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0408 - accuracy: 0.9833\n",
      "Epoch 11/28\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.0305 - accuracy: 0.9900\n",
      "Epoch 12/28\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.0217 - accuracy: 0.9867\n",
      "Epoch 13/28\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 0.0099 - accuracy: 0.9933\n",
      "Epoch 14/28\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0028 - accuracy: 1.0000\n",
      "Epoch 15/28\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.0049 - accuracy: 1.0000\n",
      "Epoch 16/28\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 17/28\n",
      "10/10 [==============================] - 1s 135ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 18/28\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 0.0021 - accuracy: 1.0000\n",
      "Epoch 19/28\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.0039 - accuracy: 0.9967\n",
      "Epoch 20/28\n",
      "10/10 [==============================] - 1s 129ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 21/28\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.0019 - accuracy: 1.0000\n",
      "Epoch 22/28\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0029 - accuracy: 1.0000\n",
      "Epoch 23/28\n",
      "10/10 [==============================] - 1s 123ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 24/28\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 25/28\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 0.0035 - accuracy: 1.0000\n",
      "Epoch 26/28\n",
      "10/10 [==============================] - 1s 128ms/step - loss: 0.0020 - accuracy: 1.0000\n",
      "Epoch 27/28\n",
      "10/10 [==============================] - 1s 126ms/step - loss: 8.9874e-04 - accuracy: 1.0000\n",
      "Epoch 28/28\n",
      "10/10 [==============================] - 1s 131ms/step - loss: 0.0020 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7d2f6da1ea90>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=n_train_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "af77b403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "100  images to be resized.\n",
      "100  images resized.\n",
      "학습데이터(x_train)의 이미지 개수는 300 입니다.\n",
      "x_test shape: (300, 28, 28, 3)\n",
      "y_test shape: (300,)\n"
     ]
    }
   ],
   "source": [
    "# x_test, y_test를 만드는 방법은 x_train, y_train을 만드는 방법과 아주 유사합니다.\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/scissor\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/rock\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test/paper\"\n",
    "resize_images(image_dir_path)\n",
    "\n",
    "image_dir_path = os.getenv(\"HOME\") + \"/aiffel/rock_scissor_paper/test\"\n",
    "(x_test, y_test)=load_data(image_dir_path)\n",
    "x_test_norm = x_test/255.0   # 입력은 0~1 사이의 값으로 정규화\n",
    "print(\"x_test shape: {}\".format(x_test.shape))\n",
    "print(\"y_test shape: {}\".format(y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7076ce78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 - 0s - loss: 12.5867 - accuracy: 0.5667\n",
      "test_loss: 12.586736679077148 \n",
      "test_accuracy: 0.5666666626930237\n"
     ]
    }
   ],
   "source": [
    "# model을 학습시키는 코드를 직접 작성해 보세요.\n",
    "# Hint! model.evaluate()을 사용해 봅시다.\n",
    "test_loss, test_accuracy = model.evaluate(x_test, y_test, verbose=2)\n",
    "print(\"test_loss: {} \".format(test_loss))\n",
    "print(\"test_accuracy: {}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e79e4a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
